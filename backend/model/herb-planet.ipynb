{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        pass\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-25T08:10:16.225952Z","iopub.execute_input":"2023-09-25T08:10:16.226825Z","iopub.status.idle":"2023-09-25T08:10:16.378935Z","shell.execute_reply.started":"2023-09-25T08:10:16.226777Z","shell.execute_reply":"2023-09-25T08:10:16.377978Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#part 1 (lets load our framework (for this note book its tf)(i wont repeat this))\nimport tensorflow as tf\n#tensorflow\nfrom tensorflow.keras import layers,Sequential,Model,utils\nimport tensorflow_hub as hub\n#we will use it later","metadata":{"execution":{"iopub.status.busy":"2023-09-25T08:10:16.381632Z","iopub.execute_input":"2023-09-25T08:10:16.382296Z","iopub.status.idle":"2023-09-25T08:10:16.387229Z","shell.execute_reply.started":"2023-09-25T08:10:16.382259Z","shell.execute_reply":"2023-09-25T08:10:16.386143Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"#part 1 (adding some callbacks)\nearlystopping=tf.keras.callbacks.EarlyStopping(\n    monitor='Accuracy',\n    min_delta=0.0001,\n    patience=2,\n    restore_best_weights=True,\n    start_from_epoch=5\n)\n\ntensorboard= tf.keras.callbacks.TensorBoard()\nchkpt = tf.keras.callbacks.ModelCheckpoint(\n    'mango.ckpt',\n    monitor = 'Accuracy',\n    save_best_only = True,\n    \n    mode = 'auto',\n    save_freq='epoch',\n)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-25T08:10:16.388748Z","iopub.execute_input":"2023-09-25T08:10:16.389205Z","iopub.status.idle":"2023-09-25T08:10:16.405226Z","shell.execute_reply.started":"2023-09-25T08:10:16.389155Z","shell.execute_reply":"2023-09-25T08:10:16.404027Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"#part 2(loading and normailizing tha data)\n# since the data is so large i will use tf.keras.utils.image_dataset_from_directory and also i will only load it as 128,128,3(for storage ressons)\n# and also i will normalize the data by going through evey single one and normalizing it as you will see below\ndf = tf.keras.utils.image_dataset_from_directory('/kaggle/input/indian-medicinal-leaves-dataset/Indian Medicinal Leaves Image Datasets/Medicinal plant dataset',\n                                            image_size=(128,128),\n                                            batch_size=16)\n# this is the normalization layer\ndef process(image,label):\n    image = tf.cast(image/255. ,tf.float32)\n    return image,label\n\ndf = df.map(process)\n#Ds means data set btw","metadata":{"execution":{"iopub.status.busy":"2023-09-25T08:10:16.408896Z","iopub.execute_input":"2023-09-25T08:10:16.409887Z","iopub.status.idle":"2023-09-25T08:10:21.182712Z","shell.execute_reply.started":"2023-09-25T08:10:16.409854Z","shell.execute_reply":"2023-09-25T08:10:21.181759Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Found 5945 files belonging to 40 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"#part 2(building the model)\n# for this model i will use the eff_net b7\nmodel_plants = Sequential([\n    layers.Input(shape=(128,128,3)),\n    hub.KerasLayer(\"https://tfhub.dev/tensorflow/efficientnet/b7/classification/1\"),\n    #the layer which loads eff_net b7\n    layers.Dense(128,activation=\"relu\"),\n    layers.Dense(40,activation='softmax')\n])","metadata":{"execution":{"iopub.status.busy":"2023-09-25T08:10:21.184190Z","iopub.execute_input":"2023-09-25T08:10:21.184536Z","iopub.status.idle":"2023-09-25T08:10:58.681577Z","shell.execute_reply.started":"2023-09-25T08:10:21.184505Z","shell.execute_reply":"2023-09-25T08:10:58.680616Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"model_plants.summary()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-25T08:10:58.683158Z","iopub.execute_input":"2023-09-25T08:10:58.683497Z","iopub.status.idle":"2023-09-25T08:10:58.731001Z","shell.execute_reply.started":"2023-09-25T08:10:58.683464Z","shell.execute_reply":"2023-09-25T08:10:58.730125Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n keras_layer (KerasLayer)    (None, 1000)              66658680  \n                                                                 \n dense (Dense)               (None, 128)               128128    \n                                                                 \n dense_1 (Dense)             (None, 40)                5160      \n                                                                 \n=================================================================\nTotal params: 66,791,968\nTrainable params: 133,288\nNon-trainable params: 66,658,680\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"#part 2 (compiling the model)\n#we will use Adam as an optimizer sparse catagorical as our loss and metrics is accuracy\nmodel_plants.compile(\n    loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n    optimizer = tf.keras.optimizers.Adam(learning_rate=0.02),\n    metrics=['Accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-25T08:10:58.732420Z","iopub.execute_input":"2023-09-25T08:10:58.733327Z","iopub.status.idle":"2023-09-25T08:10:58.752341Z","shell.execute_reply.started":"2023-09-25T08:10:58.733294Z","shell.execute_reply":"2023-09-25T08:10:58.751477Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":" with tf.device('/GPU:0'):\n    model_plants.fit(df,\n              epochs=50,\n              callbacks=[earlystopping,tensorboard,chkpt])","metadata":{"execution":{"iopub.status.busy":"2023-09-25T08:10:58.755197Z","iopub.execute_input":"2023-09-25T08:10:58.755465Z","iopub.status.idle":"2023-09-25T08:16:38.016229Z","shell.execute_reply.started":"2023-09-25T08:10:58.755442Z","shell.execute_reply":"2023-09-25T08:16:38.015072Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Epoch 1/50\n372/372 [==============================] - 131s 243ms/step - loss: 2.8380 - Accuracy: 0.2308\nEpoch 2/50\n372/372 [==============================] - 27s 72ms/step - loss: 1.8922 - Accuracy: 0.4705\nEpoch 3/50\n372/372 [==============================] - 27s 72ms/step - loss: 1.4688 - Accuracy: 0.5798\nEpoch 4/50\n372/372 [==============================] - 28s 76ms/step - loss: 1.2246 - Accuracy: 0.6421\nEpoch 5/50\n372/372 [==============================] - 28s 74ms/step - loss: 1.0514 - Accuracy: 0.6885\nEpoch 6/50\n372/372 [==============================] - 29s 76ms/step - loss: 0.9170 - Accuracy: 0.7354\nEpoch 7/50\n372/372 [==============================] - 28s 73ms/step - loss: 0.8288 - Accuracy: 0.7499\nEpoch 8/50\n372/372 [==============================] - 28s 75ms/step - loss: 0.7374 - Accuracy: 0.7791\n","output_type":"stream"}]},{"cell_type":"code","source":"# Save the model to a file\nmodel_plants.save('model_plants.h5')\n","metadata":{"execution":{"iopub.status.busy":"2023-09-25T08:27:20.856181Z","iopub.execute_input":"2023-09-25T08:27:20.856573Z","iopub.status.idle":"2023-09-25T08:27:21.998352Z","shell.execute_reply.started":"2023-09-25T08:27:20.856545Z","shell.execute_reply":"2023-09-25T08:27:21.997314Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import load_img, img_to_array\n# Load and preprocess the image\nimage_path = \"/kaggle/input/indian-medicinal-leaves-dataset/Indian Medicinal Leaves Image Datasets/Medicinal plant dataset/Aloevera/339.jpg\"\nimage = load_img(image_path, target_size=(128, 128))\nimage = img_to_array(image)\nimage = image / 255.0  # Normalize pixel values to [0, 1]\nimage = np.expand_dims(image, axis=0)  # Add batch dimension\n","metadata":{"execution":{"iopub.status.busy":"2023-09-25T08:25:57.698058Z","iopub.execute_input":"2023-09-25T08:25:57.698465Z","iopub.status.idle":"2023-09-25T08:25:57.743771Z","shell.execute_reply.started":"2023-09-25T08:25:57.698435Z","shell.execute_reply":"2023-09-25T08:25:57.742748Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"predictions = model_plants.predict(image)\npredicted_class = np.argmax(predictions[0])\n\nprint(\"Predicted class:\", predicted_class)","metadata":{"execution":{"iopub.status.busy":"2023-09-25T08:26:16.970614Z","iopub.execute_input":"2023-09-25T08:26:16.970981Z","iopub.status.idle":"2023-09-25T08:26:17.102239Z","shell.execute_reply.started":"2023-09-25T08:26:16.970951Z","shell.execute_reply":"2023-09-25T08:26:17.101344Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 0s 45ms/step\nPredicted class: 0\n","output_type":"stream"}]}]}